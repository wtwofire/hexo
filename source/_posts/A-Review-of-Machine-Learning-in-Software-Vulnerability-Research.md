---
title: A Review of Machine Learning in Software Vulnerability Research
date: 2019-04-03 16:16:36
tags:
- 综述
- 2017年
categories:
- 论文
- fuzzing
- 综述
---

# Abstract

搜索和识别计算机软件中的漏洞具有悠久而丰富的历史，可用于预防或恶意目的。在本文中，我们研究了机器学习（ML）技术在软件漏洞研究（SVR）中的应用，讨论了以前和当前的工作，以说明学术界和工业界如何利用ML。我们发现，主要关注的不仅仅是发现新方法，而是通过简化和自动化流程来帮助SVR从业者。考虑到已经证明的各种应用，我们相信ML将在未来继续为SVR提供帮助，因为探索了新的使用领域，并且可以使用改进的算法来增强现有功能。

| relevant information |                                                              |
| -------------------- | ------------------------------------------------------------ |
| *作者*               | Tamas Abraham  and Olivier de Vel                            |
| *单位*               | Cyber and Electronic Warfare Division  Principal Scientist<br/>Defence Science and Technology Group |
| *出处*               |                                                              |
| *原文地址*           |                                                              |
| *源码地址*           |                                                              |
| *发表时间*           |                                                              |

# 1. 简介

创建计算机软件是一个非常重要的复杂过程，通常会产生包含一些缺陷和脆弱点的代码。大型代码库的验证可能很困难，或者有时由于成本而被忽略，导致操作系统由于它们表现出来的意外和不良行为而可能崩溃或被操纵。虽然软件安全性错误的严重程度是可变的，但有些可能会非常严重，以至于被利用导致生产力损失，知识产权损失甚至物理损坏来对用户造成严重伤害。 Dowd等人[30]将术语软件错误中能被用于恶意目的的子类称为漏洞， 虽然在特定环境中实际利用漏洞可能并非总是可能，或者也不适合攻击者的目标。解决易受攻击软件引起的问题的方法已经在软件漏洞研究（SVR）中创建了研究。
对影响计算机系统的漏洞的研究不仅限于软件。但是，我们在本文中的重点是基于软件的漏洞，我们不考虑硬件或系统架构。软件本身可以作为源代码或二进制文件进行分析，提供多种途径来发现漏洞。软件漏洞的研究过程可以定期分为发现，分析和利用的过程，并将缓解作为预防活动[73]。每个阶段探讨了处理漏洞的不同方面，通常需要代码审计员等从业者的长期和费力的投入。自动化在许多SVR活动中起着重要作用，然而目前通过人工解释发现了大多数漏洞。越来越多的机器学习（ML）技术被整合到SVR过程中，以进一步减少对手动交互的需求。成功应用后，ML算法可以引导用户找到最可能的解决方案，并可能发现以前未知的漏洞。本文的目的是对利用机器学习的SVR内部的目录进行编目，以突出当前事业的状态，并确定可能在未来做出进一步贡献的可能领域。

# 2. 背景

本文的重点是机器学习在软件漏洞研究中的应用。为了进行讨论，我们分别介绍了两个领域和一些一般细节。在审查各个出版物时，后续章节将根据需要提供进一步的详情。接下来是对这两个研究领域的简单概述，在这个阶段，没有强调它们之间的任何联系。

## 2.1 软件漏洞研究

对软件漏洞进行分类不是一项简单的任务。特定漏洞所属的类别通常在分析软件错误期间显示。有时，在漏洞发现过程中可以预期某种类型，因为某些技术隐含地针对有限范围的漏洞类型。**扫描程序**等工具会查找错误的结构，例如过时的库函数以及代码中的其他与安全相关的错误。**模糊测试**是为软件可执行文件提供异常输入以引起意外行为（如崩溃或内存泄漏）的过程，然后可以在相应的源代码中进行调查。全面的**手动代码审查**也可用于发现错误，但它们可能是其他漏洞发现方法的昂贵替代方案。**格式校验**提供了正确性的数学证明，如果不成功，则可以指出问题。然而，由于复杂性和成本，它通常限于小代码段或算法。**符号执行**是一种分析通过程序分支遍历变量值（输入）的技术，是另一种发现方法，尽管它可能遭受诸如路径爆炸之类的扩展问题。

源代码中的一些错误可能很容易组合，尽管某些漏洞仅与其他因素（例如它们部署在其上的平台）结合使用，因此可能难以进行初始分类。计算机体系结构，操作系统，计算机语言的多样性以及语言特定错误的存在使分析更加复杂化。我们使用Dowd等人的书中给出的分类法 [30]作为定义软件漏洞类型的指南。语言特定问题包括：

- 内存损坏，例如缓冲区（堆栈，off-by-one，堆，全局和静态数据）

- 算术边界条件（如数字上溢和下溢）

- 类型转换错误（有符号/无符号，符号扩展，截断，比较）

- 操作符误用（sizeof（），移位，模数，除法）

- 指针算术错误
- 其他错误（评估顺序逻辑，结构填充，优先级，宏/预处理器，拼写错误）

其他漏洞更复杂。问题类别包括实际应用程序中存在的问题类别，例如与操作系统或应用程序平台相关的问题类别，即使基础问题可能由更简单的错误（如内存损坏或指针错误）引起：

- 字符串和元字符漏洞

- 特定于操作系统的漏洞（特权问题，文件权限问题，竞争条件，进程，IPC，线程，环境和信令问题）

- 平台漏洞（SQL注入，跨站点脚本（XSS） ），跨站点请求伪造（CSRF），文件包含和访问，shell调用，配置，访问控制和授权？aws）

对漏洞进行分类的另一种方法是从攻击角度出发。例如，Open Web Application Security Project [3]提供了一个攻击类型列表，并定期编译一系列顶级当代漏洞[1]，并非所有漏洞都与源代码或二进制文件有关。在那些注入攻击（代码，SQL，HTML脚本，远程文件和shell）和控制流劫持，如溢出（buffer，整数，字符串格式）和堆喷射类似于我们上面列出的那些。像Bletsch这样的其他作者提供类似的分类，讨论如何通过代码重用（面向返回的编程（ROP），返回到libc（RILC），面向跳转的编程（JOP））来利用漏洞[80]。 。

随着软件中的漏洞被发现，它们通常与更广泛的社区共享。The Common Vulnerabilities and Exposures  （CVE）是一个公知的信息安全漏洞和风险的库 [4]，目前由MITRE组织维护。漏洞通常附加一个分数来描述其严重性，通用漏洞评分系统（CVSS）[40]是最常用的评分标准之一。提供对CVE，分数和其他相关信息的访问的服务包括诸如开源漏洞数据库（OSVDB）和美国国家漏洞数据库（NVD）之类的数据库。和允许对新发现的漏洞进行实时更新的API（如VulnDB和vFeed）。根据不同类别中发现的漏洞数量，每年都会根据流行漏洞编制统计数据，尽管每种类型的攻击频率和严重程度之间可能没有相关性。例如，Price和Kouns [46]列出了跨站点脚本，SQL注入，跨站点请求伪造，文件包含，拒绝服务和过度攻击，这是2014年根据OSVDB最常见的滥用行为。

减轻软件漏洞影响的方法也产生了各种策略和解决方案。尽管可能无法实现完全错误预防，但软件生产商仍希望尽量减少其产品包含漏洞的可能性。这些包括在开发周期中的全面测试和修复错误，在软件发布后提供数据，以及在安全编程语言中编写代码。在Vanegue [82]中列出了在软件发布之前可以使用的漏洞发现技术列表，例如软件测试，模糊测试和程序验证（定理证明，抽象解释，模型检查）。使用抽象语法树（AST），控制流图（CFG），程序依赖图（PDG）和代码属性图（CPG）等图形建模代码执行可以帮助识别开发过程中的问题。 OS和硬件制造商也提供了软件发布后使用的其他缓解技术。数据执行保护（DEP）/不执行（NX），地址空间布局随机化（ASLR），指令集随机化（ISR），运行时检查（金丝雀，LibSafe），程序引导，控制流完整性（CFI），数据流完整性（DFI）和控制流锁定是当前使用的一些技术，参见[80]。用于执行各种发现任务的软件工具随时可用，包括商业和开源[87]。

程序分析是分析软件行为问题的核心。从理论上讲，软件错误的识别是不可判定的，即在一般情况下不可能编写程序来表示和计算另一个程序的所有可能的执行[67]。在实践中，某些程序行为可能会被忽略，因为它们与当前分析无关。然而，这可能导致在近似下 - 排除可能有效的行为，并且过度近似--包含可能但无效的行为--增加复杂性和资源需求。图1将一些程序分析技术组织到一个图表中，突出显示了各个方法的样式和自动化级别。静态分析在不执行程序的情况下进行，可以提供良好的代码覆盖率和所有可能执行的原因，但无法分析可执行环境，例如操作系统和硬件。另一方面，动态分析是在程序执行期间进行的，或者通过检测程序来分析行为。但是，它只能推断观察到的执行路径而不是所有可能的程序路径。

![](A-Review-of-Machine-Learning-in-Software-Vulnerability-Research/1.jpg)

## 2.2 机器学习

在本节中，我们简要概述了机器学习概念，并重点介绍了我们在本文后面讨论的出版物中遇到的一些相关技术。
存在许多不同的分类法用于分类ML技术。为方便起见，我们使用Barber [13]的书作为本节的参考源，除非给出了具体的参考。

机器学习领域关注数据的自动化探索，产生可用于预测的描述性模型。通常，认识到两种主要的学习方式：**监督学习**从标记数据源构建其模型并关注预测的准确性，而**无监督学习**则集中于从未标记数据提供紧凑描述。除了这两种主要风格外，还可以观察到几种变化。**异常检测**会查找与建模模型不同的数据中的异常值。随着新数据的出现，**在线学习**能够不断更新模型。**主动学习**可以通过要求来自当前模型无法有效描述的环境区域的更多数据来构建更好的模型。**强化学习**能够以反复试验的方式与环境互动，以创建根据某种形式的奖励进行优化的模型。最后，**半监督学习**利用标记和未标记的数据，使用一种类型的数据来改进可以仅从其他类型的数据创建的模型。

多年来，在上述学习方式中已经提出并开发了大量算法。监督学习主要使用多种类型的分类器中的一种来预测数据点所属的组（类）。这是一种离散学习形式，因为输出仅限于一组值。当结果需要在一个值范围内时（即它是一个连续变量），回归就是使用的技术。最简单的分类算法之一是K-最近邻（kNN）算法，它通过查看其K个最近邻居的标签并选择最常见的邻居来确定数据点的类标签，例如基于实例学习使用数据集中的示例而不是使用从中构建的模型来决定类的决策。 NaïveBayes分类器是一种概率算法，它假设描述数据的变量之间具有条件独立性，以简化生成模型的构建。点的类标签是通过使用贝叶斯规则给出不同标签的数据的概率及其条件概率来估计的。其他分类技术对数据进行线性模型，并根据与已知示例计算的决策边界相对应的数据点的位置确定类成员资格。逻辑回归是一种分类算法，它使用最大似然函数来近似属于类的数据点的概率。线性支持向量机（SVM）产生超平面以分离类，使得平面每侧上的最近点之间的距离最大化。

决策树分类器将顺序决策过程建模为特殊图形，每个节点用作特征测试，以便给定特征的不同值沿着不同的分支布置。树的叶子决定了类型成员资格。从任何特定的示例数据集中，可以构建许多不同的树，并且通常使用来自单个数据集的多个树的组合来构建更好的模型。随机森林是决策树的集合，旨在提供对作为单个树创建的模型的改进预测。图表在表示用作分类器的各种形式的神经网络（NN）[14]中也很突出。神经网络按节点层组织，包含输入层和输出层，其间有隐藏层。每个节点对应于一个函数，该函数使用分配给节点连接边的权重将其输入值映射到单个输出值。 NN分类的流行变体包括多层感知器（MLP）前馈神经网络，卷积神经网络和长期短期记忆复现神经网络。神经网络也是深度学习的核心，深度学习是一种机器学习范式，它也关注数据表示的学习。

无监督学习通常与聚类分析相关联，即基于相似性的定义将数据组织成组。这些可以包括基于数据分布的统计方法，例如使用期望最大化（EM）来构建高斯混合模型（GMM）。利用数据连接的算法是层次聚类的示例，或者是自下而上构建的，即从每个数据点开始作为集群然后是合并操作，或者自上而下，从单个集群开始并根据某种策略进行拆分。基于质心的聚类通过确定选定数量的聚类中心并将每个数据点分配给最近的聚类中心来识别聚类。另一方面，基于密度的聚类根据某个距离测量的阈值找到彼此接近的点集群，并且如果它们不满足这些要求，则可以将数据保留为未分配的噪声。Associations [5]是受市场数据分析启发的规则。它们代表了if…then构造描述数据中以某种最小所需频率出现的强模式。找到频繁项目集或特征值比其他项目更频繁地出现，可以揭示数据的趋势。顺序模式挖掘是一种具有相同目标的学习活动，但随着时间的推移分析数据，利用数据点的时间顺序来构建模型。遗传算法也是规则发现算法，它通过将交叉和变异算子应用于初始数据集并评估后续世代的精度直到满足某些终止条件来模拟自然选择。

学习通常先于预处理过程，然后是模型评估等任务。一些预处理包括特征提取，以及数据中噪声和错误的处理。特征选择和降维旨在识别与学习任务相关的特征并降低复杂性以便改进由学习算法生成的模型。有监督和无监督的学习者都可以从这个过程中受益。一些重要的例子包括主成分分析（PCA），线性判别分析（LDA），非负矩阵因子分解（NMF）和奇异值分解（SVD）。采样以减少数据大小和平衡输入数据可以提高算法的效率和性能。使用套袋和增强等集成方法可以提高单个学习算法的预测性能。出于评估目的，可以使用性能评估方法来评估算法的有效性。在二进制分类中，可以使用若干概念来描述预测条件与数据点的实际条件之间的关系。真阳性（TP）或命中，是正确预测的阳性实例。假阳性（FP）是错误预测为阳性的阴性实例。对于真阴性和假阴性，存在类似的定义。真阳性率（TPR）或算法的召回是所有阳性实例的真阳性率。精度是TP与TP和FP之和的比率，表示在预测正实例时所犯错误的数量。算法的准确性是所有数据点上正确识别的实例（TP加TN）的比率。存在许多模型评估方法，例如ROC分析[31]。结合起来，它们不仅可以提供算法评估，还可以确定其他学习策略，例如不同的特征选择方法或参数优化。

机器学习已应用于众多研究领域。可以与检查计算机程序相关的一个是自然语言处理（NLP），这是一个关注语言建模，解析和语音识别等任务的领域。可用于文档分类的一些值得注意的技术包括Latent Dirichlet Allocation（LDA）和Latent Semantic Indexing（LSI），它们都将文本建模为主题集合。

# 3.机器学习在软件漏洞中的研究

机器学习可以为软件漏洞研究等复杂的研究领域带来许多好处。它可用于模拟代码的语法和语义，并推断代码模式以分析大型代码库，协助代码审计和代码理解，同时实现可容忍的误报率。随着SVR流程复杂性的增加，对SVR从业者可用的自动化水平的需求也在增加。结果，提出了用于发现和预防目的的分析软件的新方法。其中一些是特别的。其他人使用来自其他科学领域的现成技术，包括统计学，机器学习和数据挖掘。在接下来的部分中，我们将讨论利用主要机器学习的现有工作，根据基于内容相似性的松散分组来组织它们。

我们首先指出一小部分最近的论文，这些论文考虑在更广泛的层面上解决软件漏洞问题。例如，Avgerinos等 [11]承认在广泛使用的大型软件项目中存在软件错误，例如Firefox浏览器和Linux内核，一些已知，但其他可能仍未被发现。由于在关键软件中发现了如此多的错误，作者提出了以下问题：“我们应该尝试优先修复哪些错误？”，“我们可以确定哪些是可利用的？” Jimenez等 [41]可能表明未来可能的方式。他们分析过去已知的漏洞（在本例中为Android）并建立一个分类，列出导致软件漏洞的问题，漏洞所在代码中位置的特征，这些位置的复杂性以及漏洞的复杂性。创建公共数据集，如VDiscovery [34]收集测试用例的结果，并可用于促进进一步的研究是另一项有希望的举措，众包试的寻找bug的想法这个模型由zhao等人描述[93]。

## 3.1 源代码分析

如前所述，减少SVR人类从业者的手动任务量是许多提议方法的主要目标。自动化的例子包括Parfait [26]，一个用于发现C / C ++代码中的错误的框架。 Parfa的每个bug类型都设计有多层，用于速度和可扩展性的程序分析。该解决方案背后的理念是采用更简单的分析来预测某些类型的错误，然后转向计算量更大的错误，以实现最佳的覆盖率和精度。另一个平台Mélange[74]也分享了同样的理念，同时也分析了C和C ++代码。 Mélange执行数据和控制流分析，并生成错误报告，以解释发现的错误，以帮助解决必要的问题。在执行阶段进行分析，包含局部和全局，后者按需使用以验证局部分析的结果。另一个例子是SZZ算法[88]，它被开发用于自动识别诱导修复的代码提交，并且可以被研究人员用来验证软件度量或模型以预测故障组件，这是防止bug的重要活动。

然而，这些方法是向自动化迈进并不一定依赖于机器学习技术的示例。以下类别详细说明了它们的用途。

### 3.1.1 编码实践

用于代码分析的机器学习的早期用途之一是PR-Miner [50]，数据挖掘技术的应用，为源代码构建一组编程规则。它从大型代码库（如Linux，PostgreSQL和Apache HTTP Server）生成频繁的项目集，以自动生成隐式编程规则，然后可以使用其他算法检查违规。对结果进行排序并按照假设的严重程度提供给分析师，以确定它们是否构成实际错误。这个过程很快，作者认为它能够识别比使用用户定义模板的类似工具更复杂的违规行为（例如，包含两个以上的规则组件）。 AutoISES [77]是一种类似的工具，它通过从源代码推断安全规范来检测漏洞，而不是要求手动提供这些漏洞。规范的推断仍然受到与安全编码实践相关的概念的指导，但现在根据代码中观察到的证据提取规则，并且违规被提供用于手动验证。 Linux内核和Xen用作测试用例，对于84个提取规则，发现了8个新漏洞。

协助开发人员正确使用应用程序编程接口（API）方法一直是一些论文的焦点，通常受到缺乏足够可用文档的启发。
UP-Miner工具[83]采用了几种数据挖掘方法，例如聚类和频繁闭合序列挖掘，以创建频繁的API使用模式。它还包含新的度量标准，以优化所得模式的简洁性和覆盖范围，然后将其作为概率图提供给用户以供检查和理解。与Microsoft开发人员合作对大型Microsoft代码库进行的测试证实了该方法的实用性。Nguyen等人详细介绍了另一个有趣的贡献 [59]。他们研究API前置条件，这些条件需要在调用之前通过API方法的参数来满足。他们开发了一个系统，该系统找到调用API的客户端方法，计算每个调用站点的控制依赖关系，然后挖掘用于访问这些调用站点的条件，最终推断出每个API的前提条件。使用SourceForge和Apache项目对Java Development Kit进行的大规模评估确定了书面规范中缺少的一些先决条件。此外，结果可用于识别不满足源代码中的前提条件的编码错误。本文还对早期API挖掘文献中的参考文献进行了很好的收集。

VCCFinder [62]是一个工具，它将有关代码中的漏洞的知识与有关对存储库的commits的元数据相结合，以识别可能存在漏洞的软件代码commits。为两种源类型的每个提交生成的一系列功能与已知的漏洞贡献提交案例的功能相匹配？ （VCC），从CVE的提交数据中识别，以确定新提交是否可能是漏洞的来源。为此目的构建了两级SVM。对66个GitHub项目的测试表明，与现有工具相比，误报率（FPR）大大降低，同时保持了类似的真阳性率。虽然成功识别VCC可以大大减少检查安全性的代码量，但是从业者仍然需要重要的专业知识和审核它们的手册。

















